import argparse
import dataclasses
from dataclasses import dataclass
from typing import Union
from pathlib import Path
from collections import OrderedDict
import ephys.ephys_analysis as EP
import numpy as np
import pandas as pd
#import pandasgui
from pylibrary.tools import cprint as CP

import src.set_expt_paths as set_expt_paths

cprint = CP.cprint
"""
This script makes an excel file from the .pkl (pickled Pandas) file that is
generated by DataSummary. The excel file is a "temporary" file with some default
values for analysis parameters. Typically this file will be used to seed the
main excel file for that is used to gather parameters for the IV analysis. The
main excel file will also have annotations that are not present in this file.
This file can be used to update the main file, by copying the new lines into the
main file. 

For each cell in the original file that corresponds to a IV protocol, this finds
the images in that file. Amongst the images, find the best image in the cell
directory (brightest, in this case). Finally, write to the database with the IV
file and the image file(s) indicated in new columns, with a separate row for
each IV.

Use the results of nf107_IVs (the pdf output file) to identify issues and
manually correct the images xlsx file

pbm 8/6/2018-11/2021

"""

experiments = set_expt_paths.experiments

mode = "IVs" # "Spont"  # or "IVs"
prefix = "CCIV_" # "CC_Spont"  # or "CCIV_"

# This class holds the column values for one row,
# and replaces the use of a dictionary

@dataclass
class NewRow:
    date: str = ""#  = d.iloc[index]["date"]
    slice_slice: str = "" # "] = Path(d.iloc[index]["slice_slice"]).parts[-1]
    cell_cell: str = ""# "] = Path(d.iloc[index]["cell_cell"]).parts[-1]
    iv_name: str = ""# "] = IV protocol
    reference_image: str = ""# "] = bestimage
    cell_type: str ="" #  = d.iloc[index]["cell_type"].lower()
    internal: str=""
    notes: str = ""
    bridge_amplifier: float=0.
    bridge_adjust: float=0.
    cap_comp: float=0.
    IV: Union[object, str, None] = None
    Spikes: Union[object, str, None] = None

def fix_paths(thisrow):
    """
    Because we changed the name of the path for the specific experiment...
    """
    for x in ["slice_slice", "cell_cell"]:
        thisrow[x] = thisrow[x].replace("NF107Ai32Het",  "NF107Ai32_Het")
    return thisrow
    
def check_path(experiments, experimentname, thisrow):
    # fix the data directory...
    thisrow = fix_paths(thisrow)
    dpath = Path(
        experiments[experimentname]["disk"],
        thisrow["date"],
        thisrow["slice_slice"],
        thisrow["cell_cell"],
    )
    # if not dpath.is_dir():
    #     dpath = Path(
    #         experiments[experimentname]["disk"],
    #         'Parasagittal',
    #         thisrow["date"],
    #         thisrow["slice_slice"],
    #         thisrow["cell_cell"],
    #     )
    if not dpath.is_dir():
        cprint("r", f"!!! Directory was not found on disk !!!\n    {str(dpath):s}")
        cprint("r", f"    {str(experiments[experimentname]['disk']):s}")
        print(thisrow['data_directory'])
        exit()
        return None, dpath
    return dpath, None

def _date_compare(day, date):
    """
    Compare the day to a protocol date name
    """
    if "_" not in day:
        day = day + "_000"
    if day[-1] in ["\\", "/"]:
        day = day[:-1]
    if day != date:
        # print(f"Day {day:s} did not match date: {date:s}")
        return False
    return True

def show_pkl(df):
    pass
# pandasgui.show(df)
    

def print_pkl_info(df, day, slicecell=None):
    """
    List the data in the pickled file
    """
    if day != "all":
        slicen = "slice_%03d" % int(slicecell[1])
        celln = "cell_%03d" % int(slicecell[3])
        day = str(Path(day, slicen, celln))
    for i in df.index:  # run through all entries in the db
        date = str(
            Path(
                df.at[i, "date"],
                df.at[i, "slice_slice"],
                df.at[i, "cell_cell"],
            )
        )
        if day != "all":  # if all, just do it; otherwise, build a selection
            if i == 0:
                print('looking for day: ', day, " in date: ", date)
            if _date_compare(day, str(date)):
                print(df.iloc[i])
                print("   br: ", df.iloc[i]["IV"]["BridgeAdjust"])
    exit()


def parse_database(args):
    """
    This function does all the hard work.
    """
    experimentname = args.experiment
    # print("experiments: ", experiments.keys())
    # print(experimentname)
    print(experiments[experimentname])
    # make filenames
    input_fn = Path(
        experiments[experimentname]["directory"],
        experiments[experimentname]["datasummary"],
    ).with_suffix(".pkl")
    output_fn = Path(
        experiments[experimentname]["directory"],
        experiments[experimentname][mode] + "_tmp",
    ).with_suffix(".xlsx")
    output_fn2 = Path(
        experiments[experimentname]["directory"],
        experiments[experimentname][mode] + "_tmp2",
    ).with_suffix(".xlsx")
    # read the .pkl file
    cprint('c', f"Reading main data frame from: {str(input_fn):s}")
    d = pd.read_pickle(input_fn)  # read the pandas data
    
    if args.check_pkl:
        print_pkl_info(d, args.day, args.slicecell)
        exit()

    if args.gui:
        show_pkl(d)
        exit()

    # create an empty dataframe and create columns from the dataclass NewRow
    d2 = (
        pd.DataFrame()
    )  # d.loc[:, ['date', 'slice_slice', 'cell_cell', 'data_complete']]
    newd = NewRow()
    d2keys = list(dataclasses.asdict(newd).keys())
    for k in d2.keys():
        d2[k] = newd[k]
    
    missing = []  # keep track of entries that we could not add... 
    
    # now read through the data itself
    AR = EP.acq4read.Acq4Read()
    for index in range(d.shape[0]):
        if args.day != "all":  # specified day
            day = str(args.day)
            if "_" not in day:
                day = day + "_000"
            day_x = d.iloc[index]["date"]
            if day_x != day:
                continue
            print(" dayx: ", day_x)
            cprint("yellow", f"found at day: {day:s}")

        all_ivs = d.iloc[index]["data_complete"].split(", ")
        thisrow = d.iloc[index]

        dpath, chkpath = check_path(experiments, experimentname, thisrow)
        if dpath is None:
            missing.append("r" + str(chkpath) + " path not found")
            continue
        print("\nData Directory:: ", dpath)
        supindex = AR.readDirIndex(currdir=dpath)
        if supindex is None:
            missing.append("r" + dpath + " no index found")
            cprint("red", "Continuing... no index found")
            continue
        IV_times = []
        IV_names = []
        imagetimes = []
        imagenames = []

        # look for the "best" image
        for k in supindex:
            if k.startswith("image_"):
                # print('Found Image: ', k)
                imagetimes.append(supindex[k]["__timestamp__"])
                imagenames.append(k)
            if k.startswith(prefix):
                IV_times.append(supindex[k]["__timestamp__"])
                IV_names.append(k)
                brightest = 0
                bestimage = ""
                for imno, im in enumerate(imagenames):
                    imgd = AR.getImage(Path(dpath, im))
                    avgbright = np.mean(np.mean(imgd, axis=1), axis=0)
                    if avgbright > brightest:
                        brightest = avgbright
                        bestimage = im
        # build new rows in the dataframe for each IV protocol
        # of a known type 
        for ivs in all_ivs:
            iv_protocol = Path(ivs).parts[-1]
            # print('IV: ', iv_protocol)
            if (
                iv_protocol.startswith(prefix)
            ) and len(iv_protocol) > 1:
            
                printf("  Adding protocol: {iv_protocol:s}")
                newrow = NewRow()
                cell_dat =  d.iloc[index]
                newrow.date = cell_dat["date"]
                newrow.slice_slice = Path(cell_dat["slice_slice"]).parts[-1]
                newrow.cell_cell = Path(cell_dat["cell_cell"]).parts[-1]
                newrow.cell_type = cell_dat["cell_type"].lower()
                newrow.internal = cell_dat['internal']
                newrow.notes = cell_dat["notes"]
                newrow.iv_name = iv_protocol
                newrow.reference_image = bestimage
                protname = Path(cell_dat["date"], cell_dat["slice_slice"], cell_dat["cell_cell"], iv_protocol)
                newrow.bridge_amplifier = 0.
                newrow.bridge_adjust = 0.
                newrow.cap_comp = 0.
                print("-"*80, "\nIProtocols: ")
                if isinstance(cell_dat["IV"], float):
                    cell_dat["IV"] = {}  # as in, haven't done it yet.
                    continue
                try:
                    iv_keys = list(cell_dat["IV"].keys())
                except:
                    print(cell_dat["IV"])
                    raise ValueError("Bad key for celldat!")
                if protname in iv_keys:
                    prot_data = cell_dat["IV"][protname]
                    prot_keys = list(prot_data.keys())
                    # print(prot_data)
                    if "CCComp" in prot_keys:
                        if prot_data["CCComp"]["CCBridgeEnable"] is True:  # convert to Mohm
                            newrow.bridge_amplifier = 1e-6*prot_data["CCComp"]['CCBridgeResistance']
                        if prot_data["CCComp"]["CCNeutralizationEnable"] == 1:
                            newrow.cap_comp = prot_data["CCComp"]["CCNeutralizationCap"]
                        if "BridgeAdjust" in prot_keys:
                            newrow.bridge_adjust = prot_data["BridgeAdjust"]*1e-6
                    newrow.IV = prot_data
                    newrow.Spikes = cell_dat["Spikes"][protname]
                else:
                    newrow.bridge_amplifier = 0.
                    missing.append("y" + str(protname) + "  protocol was not in dataset (probably not analyzed)")
                    missing.append("y" + f"      Age: {str(cell_dat['age']):s}  {cell_dat['sex']:s}")
                    missing.append("y" + f"      listed protocols were: {str(iv_keys):s}")
                    
                    # for ivp in list(cell_dat["IV"].keys()):
                #     print(ivp, "\n", cell_dat["IV"][ivp])
                print("="*80)
                
                d2 = d2.append(dataclasses.asdict(newrow), ignore_index=True)

    cprint("c", f"Writing to EXCEL file {str(output_fn):s}")
    d2.to_excel(output_fn, columns=d2keys)  # column parameter forces order of fields in excel file
    for m in missing:
        cprint(m[0], m[1:])
        


def main():
    """
    Handle command line paremeters: 
        - the name of the experiment, 
        - possibly just a day and/or a slice/cell from that day
    """
    parser = argparse.ArgumentParser(
        description="CC data analysis: make excel table with IVs or CC_Sponts"
    )
    parser.add_argument(
        "-E",
        "--experiment",
        type=str,
        dest="experiment",
        choices=list(set_expt_paths.experiments.keys()),
        default="None",
        nargs="?",
        const="None",
        help="Select Experiment to analyze",
    )
    parser.add_argument("-d", "--day", type=str, default="all", help="day for analysis")
    parser.add_argument(
        "-s",
        "--slice",
        type=str,
        default="",
        dest="slicecell",
        help="select slice/cell for analysis: in format: S0C1 for slice_000 cell_001\n"
        + "or S0 for all cells in slice 0",
    )
    parser.add_argument("-c", "--check", action="store_true", default=False,
        dest="check_pkl", help="Check pkl file for this entry and print out the info")

    parser.add_argument("-g", "--gui", action="store_true", default=False,
        dest="gui", help="show dataframe in pandasgui")

    args = parser.parse_args()

    parse_database(args)


if __name__ == "__main__":
    main()
